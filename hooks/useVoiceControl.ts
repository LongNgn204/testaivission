/**
 * ðŸŽ¤ ENHANCED VOICE CONTROL HOOK
 * 
 * Hook toÃ n diá»‡n Ä‘á»ƒ Ä‘iá»u khiá»ƒn app báº±ng giá»ng nÃ³i
 * TÃ­ch há»£p vá»›i VoiceCommandService vÃ  AIService
 */

import { useState, useCallback, useRef, useEffect } from 'react';
import { useNavigate } from 'react-router-dom';
import { voiceCommandService, VoiceCommand } from '../services/voiceCommandService';
import { AIService } from '../services/aiService';
import { useLanguage } from '../context/LanguageContext';
import { useTheme } from '../context/ThemeContext';
import { usePdfExport } from './usePdfExport';

interface VoiceControlState {
  isListening: boolean;
  isSpeaking: boolean;
  transcript: string;
  command: VoiceCommand | null;
  feedback: string;
  error: string | null;
}

export const useVoiceControl = () => {
  const navigate = useNavigate();
  const { language, setLanguage } = useLanguage();
  const { theme, setTheme } = useTheme();
  const { exportToPdf } = usePdfExport();
  
  const [state, setState] = useState<VoiceControlState>({
    isListening: false,
    isSpeaking: false,
    transcript: '',
    command: null,
    feedback: '',
    error: null,
  });

  const recognitionRef = useRef<any>(null);
  const aiService = useRef(new AIService());

  /**
   * Khá»Ÿi táº¡o Speech Recognition
   */
  useEffect(() => {
    if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
      setState(prev => ({ ...prev, error: 'Speech recognition not supported' }));
      return;
    }

    const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
    recognitionRef.current = new SpeechRecognition();
    
    recognitionRef.current.continuous = false;
    recognitionRef.current.interimResults = true;
    recognitionRef.current.lang = language === 'vi' ? 'vi-VN' : 'en-US';
    recognitionRef.current.maxAlternatives = 3;

    recognitionRef.current.onresult = (event: any) => {
      const results = event.results;
      const transcript = Array.from(results)
        .map((result: any) => result[0].transcript)
        .join('');
      
      setState(prev => ({ ...prev, transcript }));

      // Náº¿u lÃ  final result, parse command
      if (results[results.length - 1].isFinal) {
        handleTranscript(transcript);
      }
    };

    recognitionRef.current.onerror = (event: any) => {
      console.error('Speech recognition error:', event.error);
      setState(prev => ({ 
        ...prev, 
        isListening: false, 
        error: `Recognition error: ${event.error}` 
      }));
    };

    recognitionRef.current.onend = () => {
      setState(prev => ({ ...prev, isListening: false }));
    };

    return () => {
      if (recognitionRef.current) {
        recognitionRef.current.stop();
      }
    };
  }, [language]);

  /**
   * Xá»­ lÃ½ transcript vÃ  thá»±c thi command
   */
  const handleTranscript = useCallback(async (transcript: string) => {
    console.log('ðŸŽ¤ Transcript:', transcript);

    // Parse command
    const command = voiceCommandService.parseCommand(transcript);
    
    if (!command) {
      setState(prev => ({ 
        ...prev, 
        command: null,
        feedback: language === 'vi' ? 'KhÃ´ng hiá»ƒu lá»‡nh. Thá»­ láº¡i?' : 'Command not recognized. Try again?',
        error: 'Command not recognized'
      }));
      
      // Speak error feedback
      speakFeedback(language === 'vi' ? 'Xin lá»—i, tÃ´i khÃ´ng hiá»ƒu lá»‡nh nÃ y' : 'Sorry, I didn\'t understand that command');
      return;
    }

    console.log('âœ… Command:', command);
    
    // Get feedback message
    const feedback = voiceCommandService.getFeedbackMessage(command, language);
    setState(prev => ({ ...prev, command, feedback }));

    // Speak feedback
    await speakFeedback(feedback);

    // Execute command
    await executeCommand(command);

  }, [language, navigate, setLanguage, setTheme, exportToPdf]);

  /**
   * Thá»±c thi command
   */
  const executeCommand = useCallback(async (command: VoiceCommand) => {
    try {
      // NAVIGATION
      if (command.intent === 'navigate') {
        const routes: Record<string, string> = {
          home: '/',
          history: '/history',
          hospitals: '/hospitals',
          reminders: '/reminders',
          about: '/about',
        };
        
        const route = routes[command.target || ''];
        if (route) {
          navigate(route);
        }
        return;
      }

      // TEST
      if (command.intent === 'test') {
        const testRoutes: Record<string, string> = {
          snellen: '/test/snellen',
          colorblind: '/test/colorblind',
          astigmatism: '/test/astigmatism',
          amsler: '/test/amsler',
          duochrome: '/test/duochrome',
        };
        
        const route = testRoutes[command.target || ''];
        if (route) {
          navigate(route);
        }
        return;
      }

      // EXPORT
      if (command.intent === 'export') {
        if (command.action === 'pdf') {
          const fileName = `vision-report-${new Date().getTime()}`;
          await exportToPdf(fileName);
          await speakFeedback(
            language === 'vi' 
              ? 'ÄÃ£ xuáº¥t bÃ¡o cÃ¡o PDF thÃ nh cÃ´ng' 
              : 'PDF report exported successfully'
          );
        }
        return;
      }

      // SETTINGS
      if (command.intent === 'settings') {
        if (command.target === 'dark_mode') {
          setTheme(command.action === 'enable' ? 'dark' : 'light');
        } else if (command.target === 'language_vi') {
          setLanguage('vi');
          await speakFeedback('ÄÃ£ Ä‘á»•i sang tiáº¿ng Viá»‡t');
        } else if (command.target === 'language_en') {
          setLanguage('en');
          await speakFeedback('Changed to English');
        }
        return;
      }

      // HELP
      if (command.intent === 'help') {
        // Sáº½ trigger modal hiá»‡n help
        window.dispatchEvent(new CustomEvent('show-voice-help'));
        return;
      }

      // GENERAL
      if (command.intent === 'general') {
        if (command.action === 'stop') {
          stopListening();
        } else if (command.action === 'refresh') {
          window.location.reload();
        }
        return;
      }

    } catch (error) {
      console.error('Command execution error:', error);
      await speakFeedback(
        language === 'vi' 
          ? 'Xin lá»—i, cÃ³ lá»—i xáº£y ra khi thá»±c hiá»‡n lá»‡nh' 
          : 'Sorry, an error occurred while executing the command'
      );
    }
  }, [navigate, setLanguage, setTheme, exportToPdf, language]);

  /**
   * Speak feedback báº±ng Web Speech API
   */
  const speakFeedback = useCallback(async (text: string) => {
    setState(prev => ({ ...prev, isSpeaking: true }));

    try {
      // DÃ¹ng AIService TTS náº¿u cÃ³
      await aiService.current.generateSpeech(text, language);
    } catch (error) {
      // Fallback to Web Speech API
      if ('speechSynthesis' in window) {
        const utterance = new SpeechSynthesisUtterance(text);
        utterance.lang = language === 'vi' ? 'vi-VN' : 'en-US';
        utterance.rate = 1.0;
        utterance.pitch = 1.0;
        
        utterance.onend = () => {
          setState(prev => ({ ...prev, isSpeaking: false }));
        };

        window.speechSynthesis.speak(utterance);
      }
    }

    // Reset isSpeaking sau 3 giÃ¢y (timeout)
    setTimeout(() => {
      setState(prev => ({ ...prev, isSpeaking: false }));
    }, 3000);
  }, [language]);

  /**
   * Báº¯t Ä‘áº§u listening
   */
  const startListening = useCallback(() => {
    if (!recognitionRef.current) {
      setState(prev => ({ ...prev, error: 'Speech recognition not available' }));
      return;
    }

    try {
      // Reset state
      setState(prev => ({ 
        ...prev, 
        isListening: true, 
        transcript: '', 
        command: null,
        feedback: '',
        error: null 
      }));

      // Update language
      recognitionRef.current.lang = language === 'vi' ? 'vi-VN' : 'en-US';
      
      // Start recognition
      recognitionRef.current.start();

      console.log('ðŸŽ¤ Voice control started');
    } catch (error) {
      console.error('Start listening error:', error);
      setState(prev => ({ ...prev, isListening: false, error: 'Failed to start listening' }));
    }
  }, [language]);

  /**
   * Dá»«ng listening
   */
  const stopListening = useCallback(() => {
    if (recognitionRef.current) {
      recognitionRef.current.stop();
    }
    setState(prev => ({ ...prev, isListening: false }));
    console.log('ðŸŽ¤ Voice control stopped');
  }, []);

  /**
   * Toggle listening
   */
  const toggleListening = useCallback(() => {
    if (state.isListening) {
      stopListening();
    } else {
      startListening();
    }
  }, [state.isListening, startListening, stopListening]);

  return {
    ...state,
    startListening,
    stopListening,
    toggleListening,
    speakFeedback,
  };
};
