import React, { useState, useRef, useEffect, useCallback } from 'react';
import { useNavigate } from 'react-router-dom';
import { X, Bot, Mic, MicOff, Volume2 } from 'lucide-react';
import { useLanguage } from '../../context/LanguageContext';
import { useRoutine } from '../../context/RoutineContext';
import { StorageService } from '../../services/storageService';
import { ChatbotService } from '../../services/chatbotService';
import { useSpeechRecognition } from '../../hooks/useSpeechRecognition';

const storageService = new StorageService();

interface VoiceInterfaceProps {
    isOpen: boolean;
    onClose: () => void;
}

/**
 * Free Voice Chat Interface
 * Uses:
 * - Browser Web Speech API for Speech Recognition (STT)
 * - Cloudflare Workers AI (GPT-OSS-120B) for AI response - FREE!
 * - Browser SpeechSynthesis for Text-to-Speech (TTS)
 * 
 * NO API KEY REQUIRED!
 */
export const VoiceInterface: React.FC<VoiceInterfaceProps> = ({ isOpen, onClose }) => {
    const { t, language } = useLanguage();
    const { userProfile } = useRoutine();
    const navigate = useNavigate();

    const [status, setStatus] = useState<'idle' | 'listening' | 'thinking' | 'speaking'>('idle');
    const [botTranscript, setBotTranscript] = useState('');
    
    // Ch√∫ th√≠ch: d√πng hook useSpeechRecognition ƒë·ªÉ qu·∫£n l√Ω STT
    const speechRecognition = useSpeechRecognition(language);
    const { isSupported: isSpeechSupported, isListening, interimText, finalText, error: speechError, start: startSTT, stop: stopSTT, reset: resetSTT } = speechRecognition;
    
    const [error, setError] = useState<string | null>(null);
    const lastSentTextRef = useRef<string>('');
    const chatbotService = useRef(new ChatbotService());

    // Check if speech synthesis is supported
    const isSynthesisSupported = typeof window !== 'undefined' && 'speechSynthesis' in window;

    // Ch√∫ th√≠ch: TTS v·ªõi callback ƒë·ªÉ restart listening sau khi n√≥i xong
    const speak = useCallback((text: string) => {
        if (!isSynthesisSupported || !text) return;

        setStatus('speaking');
        setBotTranscript(text);

        // Ch√∫ th√≠ch: d√πng SpeechSynthesis v·ªõi callback ƒë·ªÉ restart listening
        const synth = window.speechSynthesis;
        synth.cancel();

        const utterance = new SpeechSynthesisUtterance(text);
        utterance.lang = language === 'vi' ? 'vi-VN' : 'en-US';
        utterance.rate = 1.0;
        utterance.pitch = 1.0;

        utterance.onend = () => {
            setStatus('listening');
            setBotTranscript('');
            // Restart listening sau khi n√≥i xong
            if (isOpen) {
                startSTT();
            }
        };

        utterance.onerror = () => {
            setStatus('listening');
            if (isOpen) {
                startSTT();
            }
        };

        synth.speak(utterance);
    }, [language, isSynthesisSupported, isOpen, startSTT]);

    // Process voice command and handle navigation/tests
    const processCommand = useCallback((transcript: string): boolean => {
        const lower = transcript.toLowerCase();

        // Test commands
        const testMap: Record<string, string> = {
            'snellen': 'snellen',
            'th·ªã l·ª±c': 'snellen',
            'visual acuity': 'snellen',
            'm√π m√†u': 'colorblind',
            'color blind': 'colorblind',
            'colorblind': 'colorblind',
            'lo·∫°n th·ªã': 'astigmatism',
            'astigmatism': 'astigmatism',
            'amsler': 'amsler',
            'ho√†ng ƒëi·ªÉm': 'amsler',
            'macular': 'amsler',
            'duochrome': 'duochrome',
            'hai m√†u': 'duochrome',
        };

        for (const [keyword, test] of Object.entries(testMap)) {
            if (lower.includes(keyword) && (lower.includes('test') || lower.includes('ki·ªÉm tra') || lower.includes('l√†m'))) {
                const msg = language === 'vi'
                    ? `ƒêang b·∫Øt ƒë·∫ßu b√†i ki·ªÉm tra ${test}...`
                    : `Starting ${test} test...`;
                setBotTranscript(msg);
                speak(msg);
                setTimeout(() => {
                    navigate(`/home/test/${test}`);
                    onClose();
                }, 1500);
                return true;
            }
        }

        // Navigation commands
        const navMap: Record<string, string> = {
            'l·ªãch s·ª≠': 'history',
            'history': 'history',
            'ti·∫øn tr√¨nh': 'progress',
            'progress': 'progress',
            'nh·∫Øc nh·ªü': 'reminders',
            'reminders': 'reminders',
            'b·ªánh vi·ªán': 'hospitals',
            'hospitals': 'hospitals',
            'trang ch·ªß': '',
            'home': '',
        };

        for (const [keyword, page] of Object.entries(navMap)) {
            if (lower.includes(keyword)) {
                const msg = language === 'vi'
                    ? `ƒêang chuy·ªÉn ƒë·∫øn ${keyword}...`
                    : `Navigating to ${keyword}...`;
                setBotTranscript(msg);
                speak(msg);
                setTimeout(() => {
                    navigate(`/home${page ? '/' + page : ''}`);
                    onClose();
                }, 1500);
                return true;
            }
        }

        return false;
    }, [language, navigate, onClose, speak]);

    // Send message to AI and speak response
    const sendToAI = useCallback(async (text: string) => {
        if (!text.trim()) return;

        setStatus('thinking');
        stopSTT(); // Ch√∫ th√≠ch: d·ª´ng STT khi ƒëang suy nghƒ©

        try {
            const history = storageService.getTestHistory();
            const context = history.length > 0 ? history[0] : null;

            const response = await chatbotService.current.chat(text, context, userProfile, language);

            speak(response);
        } catch (err: any) {
            console.error('Voice AI error:', err);
            const errorMsg = language === 'vi'
                ? 'Xin l·ªói, ƒë√£ c√≥ l·ªói x·∫£y ra. Vui l√≤ng th·ª≠ l·∫°i.'
                : 'Sorry, an error occurred. Please try again.';
            speak(errorMsg);
        }
    }, [language, userProfile, speak, stopSTT]);

    // Ch√∫ th√≠ch: theo d√µi finalText v√† g·ª≠i khi c√≥ thay ƒë·ªïi m·ªõi
    useEffect(() => {
        if (finalText && finalText !== lastSentTextRef.current && finalText.trim()) {
            const textToSend = finalText.trim();
            lastSentTextRef.current = textToSend;

            // Check if it's a command first
            if (!processCommand(textToSend)) {
                // Not a command, send to AI
                sendToAI(textToSend);
            }
            
            // Reset STT ƒë·ªÉ chu·∫©n b·ªã cho l·∫ßn n√≥i ti·∫øp theo
            resetSTT();
            lastSentTextRef.current = '';
        }
    }, [finalText, processCommand, sendToAI, resetSTT]);

    // Ch√∫ th√≠ch: sync status v·ªõi isListening t·ª´ hook
    useEffect(() => {
        if (isListening && status !== 'thinking' && status !== 'speaking') {
            setStatus('listening');
        } else if (!isListening && status === 'listening') {
            setStatus('idle');
        }
    }, [isListening, status]);

    // Ch√∫ th√≠ch: sync error t·ª´ hook
    useEffect(() => {
        if (speechError) {
            setError(speechError);
        }
    }, [speechError]);

    // Start listening
    const startListening = useCallback(() => {
        if (!isSpeechSupported) {
            setError(language === 'vi'
                ? 'Tr√¨nh duy·ªát kh√¥ng h·ªó tr·ª£ nh·∫≠n di·ªán gi·ªçng n√≥i'
                : 'Browser does not support speech recognition');
            return;
        }
        setError(null);
        startSTT();
    }, [isSpeechSupported, language, startSTT]);

    // Stop listening
    const stopListening = useCallback(() => {
        stopSTT();
        if (typeof window !== 'undefined' && window.speechSynthesis) {
            window.speechSynthesis.cancel();
        }
        setStatus('idle');
    }, [stopSTT]);

    // Toggle listening
    const toggleListening = useCallback(() => {
        if (status === 'listening') {
            stopListening();
        } else if (status === 'idle') {
            startListening();
        }
    }, [status, startListening, stopListening]);

    // Cleanup on close
    useEffect(() => {
        if (!isOpen) {
            stopListening();
            resetSTT();
            setBotTranscript('');
            setError(null);
            lastSentTextRef.current = '';
        }
    }, [isOpen, stopListening, resetSTT]);

    // Auto-start listening when opened
    useEffect(() => {
        if (isOpen && status === 'idle' && !error) {
            // Small delay to ensure modal is visible
            const timer = setTimeout(startListening, 500);
            return () => clearTimeout(timer);
        }
    }, [isOpen]);

    // Load voices
    useEffect(() => {
        if (isSynthesisSupported) {
            speechSynthesis.getVoices();
            speechSynthesis.onvoiceschanged = () => speechSynthesis.getVoices();
        }
    }, [isSynthesisSupported]);

    const getStatusText = () => {
        switch (status) {
            case 'listening': return language === 'vi' ? 'üé§ ƒêang nghe...' : 'üé§ Listening...';
            case 'thinking': return language === 'vi' ? 'ü§î ƒêang suy nghƒ©...' : 'ü§î Thinking...';
            case 'speaking': return language === 'vi' ? 'üîä ƒêang n√≥i...' : 'üîä Speaking...';
            default: return language === 'vi' ? 'Nh·∫•n ƒë·ªÉ n√≥i' : 'Tap to speak';
        }
    };

    const getStatusColor = () => {
        switch (status) {
            case 'listening': return 'from-green-400 to-emerald-600';
            case 'thinking': return 'from-yellow-400 to-orange-500';
            case 'speaking': return 'from-blue-400 to-indigo-600';
            default: return 'from-gray-400 to-gray-600';
        }
    };

    if (!isOpen) return null;

    return (
        <div className="fixed inset-0 bg-black/80 backdrop-blur-sm z-50 flex flex-col items-center justify-center animate-fade-in p-4">
            {/* Close button */}
            <button
                onClick={onClose}
                className="absolute top-6 right-6 text-white/70 hover:text-white transition-colors p-2 rounded-full hover:bg-white/10"
            >
                <X size={32} />
            </button>

            <div className="flex flex-col items-center justify-center text-center text-white flex-grow w-full max-w-2xl">

                {/* Error message */}
                {error && (
                    <div className="mb-6 p-4 bg-red-500/20 border border-red-500/50 rounded-lg text-red-200">
                        {error}
                    </div>
                )}

                {/* Visualizer */}
                <div
                    onClick={toggleListening}
                    className={`relative w-48 h-48 rounded-full flex items-center justify-center cursor-pointer
                        transition-all duration-500 ${status === 'listening' ? 'scale-110' : 'scale-100'}
                        bg-gradient-to-br ${getStatusColor()} shadow-2xl`}
                >
                    {/* Pulse animation */}
                    {status === 'listening' && (
                        <>
                            <div className="absolute inset-0 rounded-full bg-green-500/30 animate-ping"></div>
                            <div className="absolute inset-0 rounded-full bg-green-500/20 animate-pulse"></div>
                        </>
                    )}

                    {/* Icon */}
                    <div className="relative z-10">
                        {status === 'listening' ? (
                            <Mic size={64} className="text-white animate-pulse" />
                        ) : status === 'speaking' ? (
                            <Volume2 size={64} className="text-white" />
                        ) : status === 'thinking' ? (
                            <Bot size={64} className="text-white animate-bounce" />
                        ) : (
                            <MicOff size={64} className="text-white/70" />
                        )}
                    </div>
                </div>

                {/* Status text */}
                <p className="mt-8 text-2xl font-light tracking-wide text-white/90">
                    {getStatusText()}
                </p>

                {/* Transcripts */}
                <div className="mt-8 min-h-[120px] space-y-4 px-4 w-full">
                    {(interimText || finalText) && (
                        <div className="bg-white/10 rounded-lg p-4 animate-fade-in">
                            <p className="text-sm text-gray-400 mb-1">
                                {language === 'vi' ? 'B·∫°n n√≥i:' : 'You said:'}
                            </p>
                            <p className="text-lg text-white">
                                {finalText && <span>"{finalText}"</span>}
                                {interimText && !finalText && <span className="text-gray-400">"{interimText}"</span>}
                            </p>
                        </div>
                    )}

                    {botTranscript && (
                        <div className="bg-green-500/20 rounded-lg p-4 animate-fade-in">
                            <p className="text-sm text-green-300 mb-1">
                                {language === 'vi' ? 'B√°c sƒ© Eva:' : 'Dr. Eva:'}
                            </p>
                            <p className="text-lg text-white">{botTranscript}</p>
                        </div>
                    )}
                </div>

                {/* Instructions */}
                <div className="mt-8 text-white/50 text-sm max-w-md">
                    <p>{language === 'vi'
                        ? 'B·∫°n c√≥ th·ªÉ h·ªèi v·ªÅ s·ª©c kh·ªèe m·∫Øt, ho·∫∑c n√≥i "l√†m test Snellen", "xem l·ªãch s·ª≠"...'
                        : 'Ask about eye health, or say "start Snellen test", "show history"...'}
                    </p>
                </div>

                {/* Mic Button for repeated speaking */}
                {(status === 'speaking' || status === 'idle') && (
                    <button
                        onClick={startListening}
                        className="mt-6 flex items-center gap-2 px-6 py-3 bg-green-500/20 hover:bg-green-500/40 border border-green-500/50 rounded-full text-green-300 font-medium transition-all"
                    >
                        <Mic size={20} />
                        {language === 'vi' ? 'Nh·∫•n ƒë·ªÉ n√≥i ti·∫øp' : 'Tap to speak again'}
                    </button>
                )}
            </div>

            {/* Footer */}
            <div className="mb-8 text-center">
                <p className="text-sm text-white/40 font-light tracking-widest uppercase">
                    {language === 'vi' ? 'B√°c sƒ© Eva - Tr·ª£ l√Ω AI' : 'Dr. Eva - AI Assistant'}
                </p>
            </div>

            <style>{`
                .animate-fade-in { animation: fadeIn 0.3s ease-out both; }
                @keyframes fadeIn { 
                    0% { opacity: 0; transform: translateY(10px); } 
                    100% { opacity: 1; transform: translateY(0); } 
                }
            `}</style>
        </div>
    );
};
