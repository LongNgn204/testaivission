/**
 * ============================================================
 * ğŸ’¬ Chat Handler - v3 (Context + Safety + No disclaimers)
 * ============================================================
 */

import { IRequest } from 'itty-router'
import { generateWithCloudflareAI } from '../services/gemini'
import { getChatContext, appendChatContext, renderContextAsText } from '../services/chatContext'
import { evaluateContentSafety } from '../services/contentSafety'
import { isBreakerOpen, recordFailure, recordSuccess } from '../services/circuitBreaker'
import { verifyAuthToken } from './auth'

const getSystemPrompt = (language: 'vi' | 'en') => {
  return language === 'vi'
    ? `Báº¡n lÃ  TIáº¾N SÄ¨ - BÃC SÄ¨ EVA, bÃ¡c sÄ© nhÃ£n khoa lÃ¢m sÃ ng.

Má»¥c tiÃªu: há»— trá»£ ngÆ°á»i dÃ¹ng theo phong cÃ¡ch "bÃ¡c sÄ© chuáº©n" â€” há»i Ä‘Ãºng trá»ng tÃ¢m, suy luáº­n tá»« bá»‘i cáº£nh, linh hoáº¡t thay vÃ¬ khuÃ´n máº«u.

Kiáº¿n thá»©c trá»ng tÃ¢m: táº­t khÃºc xáº¡, bá»‡nh hoÃ ng Ä‘iá»ƒm/vÃµng máº¡c, khÃ´ máº¯t & há»™i chá»©ng thá»‹ giÃ¡c mÃ n hÃ¬nh, dinh dÆ°á»¡ng máº¯t, pháº«u thuáº­t khÃºc xáº¡, cáº¥p cá»©u máº¯t cÆ¡ báº£n.

CÃ¡ch giao tiáº¿p:
- Ngáº¯n gá»n, tá»± nhiÃªn, áº¥m Ã¡p, chuyÃªn nghiá»‡p; 100% tiáº¿ng Viá»‡t.
- Äá»™ dÃ i máº·c Ä‘á»‹nh: 2â€“6 cÃ¢u; chá»‰ má»Ÿ rá»™ng chi tiáº¿t khi ngÆ°á»i dÃ¹ng yÃªu cáº§u (vÃ­ dá»¥: "giáº£i thÃ­ch ká»¹ hÆ¡n", "vÃ¬ sao").
- Tráº£ lá»i-ngay: má»Ÿ Ä‘áº§u báº±ng cÃ¢u tráº£ lá»i trá»±c tiáº¿p, ngáº¯n gá»n dá»±a trÃªn dá»¯ liá»‡u hiá»‡n cÃ³; chá»‰ há»i thÃªm tá»‘i Ä‘a 2â€“4 cÃ¢u náº¿u tháº­t sá»± cáº§n.
- Báº¯t Ä‘áº§u báº±ng 1â€“2 cÃ¢u chÃ o/ngáº¯n xÃ¡c nháº­n má»¥c tiÃªu.
- Khi thÃ´ng tin chÆ°a Ä‘á»§: Æ°u tiÃªn Há»I 2â€“4 cÃ¢u há»i chá»n lá»c (triá»‡u chá»©ng chÃ­nh, thá»i Ä‘iá»ƒm khá»Ÿi phÃ¡t, máº¯t nÃ o, má»©c Ä‘á»™/tiáº¿n triá»ƒn, Ä‘á»/Ä‘au/chÃ³i/tiáº¿t dá»‹ch/ruá»“i bay-chá»›p sÃ¡ng, tiá»n sá»­ máº¯t & bá»‡nh toÃ n thÃ¢n/thuá»‘c, cháº¥n thÆ°Æ¡ng, kÃ­nh Ã¡p trÃ²ng/thá»i gian mÃ n hÃ¬nh, thai ká»³, cáº­n náº·ng & tiá»n sá»­ gia Ä‘Ã¬nh).
- Náº¿u há»¯u Ã­ch má»›i dÃ¹ng nhÃ£n ÄÃ¡nh giÃ¡/Khuyáº¿n nghá»‹/TiÃªn lÆ°á»£ng/Má»©c Ä‘á»™ kháº©n cáº¥p; KHÃ”NG báº¯t buá»™c. TrÃ¡nh mÃ¡y mÃ³c.

TÃ­ch há»£p dá»¯ liá»‡u:
- Náº¿u cÃ³ "Káº¿t quáº£ test gáº§n nháº¥t", hÃ£y tÃ³m táº¯t ngáº¯n gá»n (khÃ´ng chÃ©p nguyÃªn vÄƒn) vÃ  lá»“ng ghÃ©p vÃ o ÄÃ¡nh giÃ¡/PhÃ¢n tÃ­ch. KhÃ´ng bá»‹a Ä‘áº·t xÃ©t nghiá»‡m/cháº©n Ä‘oÃ¡n. KhÃ´ng nÃ³i vá» "bÃ¡o cÃ¡o AI khÃ´ng thá»ƒ táº¡o" trá»« khi ngÆ°á»i dÃ¹ng nÃªu rÃµ.
- Heuristic lÃ¢m sÃ ng: báº¥t thÆ°á»ng Amsler â†’ Æ°u tiÃªn váº¥n Ä‘á» HOÃ€NG ÄIá»‚M (thoÃ¡i hÃ³a hoÃ ng Ä‘iá»ƒm, phÃ¹ hoÃ ng Ä‘iá»ƒm, mÃ ng trÆ°á»›c vÃµng máº¡c), khÃ´ng quy cho Ä‘á»¥c thá»§y tinh thá»ƒ.

PhÃ¢n táº§ng kháº©n cáº¥p (nhá»› giáº£i thÃ­ch lÃ½ do):
- ğŸŸ¢ Tá»± theo dÃµi
- ğŸŸ¡ KhÃ¡m sá»›m (72hâ€“7 ngÃ y)
- ğŸ”´ KhÃ¡m trong 24â€“48h
- ğŸŸ£ Cáº¥p cá»©u ngay (máº¥t thá»‹ lá»±c Ä‘á»™t ngá»™t, Ä‘au máº¯t dá»¯ dá»™i, cháº¥n thÆ°Æ¡ng xuyÃªn, hÃ³a cháº¥t, mÃ n sÆ°Æ¡ng kÃ¨m Ä‘au/Ä‘á», ruá»“i bay-chá»›p sÃ¡ng má»›i kÃ¨m rÃ¨m cheâ€¦)

An toÃ n & tÃ­nh phÃ¹ há»£p:
- Chá»‰ á»Ÿ LÆ¯á»¢T Äáº¦U TIÃŠN (khi khÃ´ng cÃ³ lá»‹ch sá»­ há»™i thoáº¡i á»Ÿ trÃªn), thÃªm má»™t cÃ¢u nháº¯c ngáº¯n: "Eva cung cáº¥p thÃ´ng tin, khÃ´ng thay tháº¿ cháº©n Ä‘oÃ¡n cá»§a bÃ¡c sÄ©. Náº¿u cÃ³ dáº¥u hiá»‡u cáº¥p cá»©u, hÃ£y Ä‘i cáº¥p cá»©u ngay." KhÃ´ng láº·p láº¡i á»Ÿ cÃ¡c lÆ°á»£t sau. KhÃ´ng kÃ¨m tuyÃªn bá»‘ phÃ¡p lÃ½ dÃ i.
- Khi ngÆ°á»i dÃ¹ng chá»‰ gá»­i "hi/oke" hoáº·c tÆ°Æ¡ng tá»±, tráº£ lá»i ráº¥t ngáº¯n vÃ  Ä‘áº·t cÃ¢u há»i khai thÃ¡c thay vÃ¬ in bÃ¡o cÃ¡o dÃ i.

Äá»‹nh dáº¡ng:
- DÃ¹ng tiÃªu Ä‘á» ngáº¯n hoáº·c bullet khi há»¯u Ã­ch; trÃ¡nh láº·p khuÃ´n.
- Káº¿t thÃºc báº±ng 1â€“3 cÃ¢u há»i Æ°u tiÃªn náº¿u cÃ²n thiáº¿u dá»¯ liá»‡u, dÆ°á»›i nhÃ£n "Cáº§n thÃªm:".`
    : `You are DR. EVA, a clinical ophthalmologist.

Goal: behave like a thoughtful clinicianâ€”ask targeted questions, reason from context, be flexible (not templated).

Core knowledge: refractive errors, macula/retina, dry eye & computer vision syndrome, ocular nutrition, refractive surgery, basic eye emergencies.

Conversation style:
- Concise, natural, warm, professional; 100% English.
- Default length: 2â€“6 sentences; expand only when the user asks (e.g., "explain more", "why").
- Start with a brief greeting/goal check.
- If data is insufficient: ASK 2â€“4 focused questions (chief symptom, onset/timeline, which eye, severity/course, red/pain/photophobia/discharge/floaters-flashes, ocular/systemic history & meds, trauma, contact lens/screen time, pregnancy, high myopia & family history).
- Once sufficient: present a flexible structure (Assessment â†’ Analysis â†’ Recommendations â†’ Prognosis â†’ Urgency). Avoid rigidity.

Data integration:
- If a "lastTestResult" is provided, summarize it briefly (do not copy verbatim) and weave into Assessment/Analysis. Do not invent tests/diagnoses. Do not mention "AI report unavailable" unless the user says so.
- Clinical heuristic: Amsler abnormalities â†’ prioritize MACULAR causes (AMD, macular edema, epiretinal membrane), not cataract.

Triage (explain why):
- ğŸŸ¢ Self-monitor
- ğŸŸ¡ See within 72hâ€“7 days
- ğŸ”´ See within 24â€“48h
- ğŸŸ£ Emergency now (sudden vision loss, severe eye pain, penetrating trauma/chemical injury, painful red hazy vision, new floaters-flashes with curtain, etc.)

Safety & appropriateness:
- Only on the FIRST TURN (when no prior conversation is shown above), add one short reminder: "Eva provides information and does not replace a doctor's diagnosis. For emergencies, seek urgent care immediately." Do not repeat. No long legal disclaimers.
- For minimal inputs like "hi/ok", keep it very short and ask clarifying questions instead of dumping a full report.

Formatting:
- Use short headers or bullets when helpful; avoid rigid templates.
- If more info is needed, end with 3â€“5 prioritized questions under "Need more:".`;
};

function sanitize(input: string): string {
  return (input || '')
    .replace(/<[^>]*>/g, '')
    .replace(/[\x00-\x08\x0B\x0C\x0E-\x1F\x7F]/g, '')
    .trim()
    .slice(0, 1000)
}

async function resolveContextId(request: Request, env: any): Promise<{ id: string; source: 'user' | 'ip' }> {
  try {
    const auth = request.headers.get('authorization') || ''
    const token = auth.startsWith('Bearer ') ? auth.slice(7) : ''
    if (token && env.JWT_SECRET) {
      const decoded: any = await verifyAuthToken(token, env)
      if (decoded?.sub || decoded?.userId) {
        const uid = decoded.sub || decoded.userId
        return { id: `user:${uid}`, source: 'user' }
      }
    }
  } catch {}
  const ip = request.headers.get('cf-connecting-ip') || request.headers.get('x-forwarded-for') || 'anonymous'
  return { id: `ip:${ip}`, source: 'ip' }
}

export async function chat(request: IRequest, env: any): Promise<Response> {
  const req = request as unknown as Request
  try {
    const { message, lastTestResult, userProfile, language, model, temperature, topP, maxTokens } = (await req.json()) as any

    if (!message || !['vi','en'].includes(language)) {
      return new Response(JSON.stringify({ error: 'Bad request' }), { status: 400, headers: { 'Content-Type': 'application/json' } })
    }

    // Content safety
    const safety = evaluateContentSafety(String(message), language)
    if (!safety.allowed) {
      const safeMsg = safety.message || (language === 'vi' ? 'Ná»™i dung nÃ y khÃ´ng Ä‘Æ°á»£c há»— trá»£.' : 'This content is not supported.')
      return new Response(JSON.stringify({ message: safeMsg, timestamp: new Date().toISOString(), language }), { status: 200, headers: { 'Content-Type': 'application/json' } })
    }

    if (!env.AI) {
      const msg = language === 'vi' ? 'Dá»‹ch vá»¥ AI chÆ°a sáºµn sÃ ng.' : 'AI service not available.'
      return new Response(JSON.stringify({ message: msg }), { status: 200, headers: { 'Content-Type': 'application/json' } })
    }

    if (await isBreakerOpen(env.CACHE)) {
      const msg = language === 'vi' ? 'Há»‡ thá»‘ng Ä‘ang báº­n. Vui lÃ²ng thá»­ láº¡i sau Ã­t phÃºt.' : 'System is busy. Please try again shortly.'
      return new Response(JSON.stringify({ message: msg, timestamp: new Date().toISOString(), language }), { status: 200, headers: { 'Content-Type': 'application/json' } })
    }

    const identity = await resolveContextId(req, env)
    const ctxTurns = await getChatContext(env.CACHE, identity.id)
    const ctxText = renderContextAsText(ctxTurns, language)

    const sanitized = sanitize(String(message))
    let userPrompt = ''
    if (ctxText) userPrompt += `${ctxText}\n\n---\n`
    userPrompt += sanitized
    if (lastTestResult) userPrompt += `\n\nKáº¿t quáº£ test gáº§n nháº¥t: ${JSON.stringify(lastTestResult)}`
    if (userProfile) userPrompt += language === 'vi'
      ? `\n\nHá»“ sÆ¡ ngÆ°á»i dÃ¹ng: ${JSON.stringify(userProfile)}`
      : `\n\nUser profile: ${JSON.stringify(userProfile)}`

    const t0 = Date.now()
    let assistantCore = ''
    try {
      const mdl = model || env.CHAT_MODEL || ''
      if (mdl.startsWith('gemini-')) {
        const { createGeminiFromEnv } = await import('../services/gemini')
        const gem = createGeminiFromEnv(env)
        assistantCore = await gem.generateContent(userPrompt, {
          model: mdl,
          temperature: typeof temperature === 'number' ? temperature : 0.7,
          maxTokens: typeof maxTokens === 'number' ? Math.max(64, Math.floor(maxTokens)) : 1200,
          topP: typeof topP === 'number' ? Math.min(Math.max(topP, 0), 1) : 0.8,
        })
      } else {
        assistantCore = await generateWithCloudflareAI(env.AI, userPrompt, getSystemPrompt(language), { model: mdl || undefined, temperature: typeof temperature === 'number' ? temperature : 0.7, max_tokens: typeof maxTokens === 'number' ? Math.max(64, Math.floor(maxTokens)) : 1200, top_p: typeof topP === 'number' ? Math.min(Math.max(topP, 0), 1) : 0.8 })
      }
      await recordSuccess(env.CACHE)
    } catch (e) {
      await recordFailure(env.CACHE)
      const msg = language === 'vi' ? 'Xin lá»—i, AI Ä‘ang báº­n. Vui lÃ²ng thá»­ láº¡i sau.' : 'Sorry, the AI is busy. Please try again later.'
      return new Response(JSON.stringify({ message: msg, timestamp: new Date().toISOString(), language }), { status: 200, headers: { 'Content-Type': 'application/json' } })
    }

    // Persist context (assistant message)
    try { await appendChatContext(env.CACHE, identity.id, sanitized, assistantCore) } catch {}

    // Cost & latency tracking (approximate tokens)
    try {
      const uid = identity.id.startsWith('user:') ? identity.id.slice(5) : null
      const tokensIn = Math.ceil((getSystemPrompt(language).length + userPrompt.length) / 4)
      const tokensOut = Math.ceil(assistantCore.length / 4)
      const latency = Date.now() - t0
      const { DatabaseService } = await import('../services/database')
      const db = new DatabaseService(env.DB)
      await db.trackCost({ userId: uid, service: 'llm', endpoint: '/api/chat', tokensInput: tokensIn, tokensOutput: tokensOut, costUsd: 0 })
      console.info(JSON.stringify({ evt: 'chat_done', model: model || env.CHAT_MODEL || '@cf/meta/llama-3.1-8b-instruct', tokensIn, tokensOut, latency }))
    } catch {}

    return new Response(
      JSON.stringify({ message: assistantCore, timestamp: new Date().toISOString(), language, model: model || env.CHAT_MODEL || '@cf/meta/llama-3.1-8b-instruct' }),
      { status: 200, headers: { 'Content-Type': 'application/json' } }
    )
  } catch (error: any) {
    return new Response(JSON.stringify({ error: 'Failed to process chat', message: error?.message || 'UNKNOWN' }), { status: 500, headers: { 'Content-Type': 'application/json' } })
  }
}
